---
title: "Classification: LDA and QDA"
format: 
  html:
    code-fold: true
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: visual
execute:
  message: false
---

# Instructions

You will submit an HTML document to Canvas as your final version.

## Getting Started

[Download starter .qmd file](03-Classification-template.qmd)

You'll notice in the template's YAML there are specifications for how the code should be included (i.e., `code-fold: true`, `code-line-numbers: true`, `code-tools: true`). **Do not change these specifications.**

::: callout-caution
# Within your document make sure that only relevant output is printed

Do not, for example, print the preview (e.g., `head(data)`) or an entire dataset in your final knitted file.
:::

::: callout-tip
# Organization

Your document should also be clearly organized, so that it is easy for a reader to find your answers to each question. If I have a difficult time locating or reading your answer, you risk it being returned with a "revision requested".
:::

```{r}
#| label: libraries-r
#| include: false
library(tidyverse)
library(tidymodels)
library(glmnet)
library(discrim)
```

# LDA

In this lab, we will use medical data to predict the likelihood of a person experiencing an exercise-induced heart attack.

Our dataset consists of clinical data from patients who entered the hospital complaining of chest pain ("angina") during exercise. The information collected includes:

-   `age` : Age of the patient

-   `sex` : Sex of the patient

-   `cp` : Chest Pain type

    -   Value 1: typical angina
    -   Value 2: atypical angina
    -   Value 3: non-anginal pain
    -   Value 4: asymptomatic

-   `trtbps` : resting blood pressure (in mm Hg)

-   `chol` : cholesterol in mg/dl fetched via BMI sensor

-   `restecg` : resting electrocardiographic results

    -   Value 0: normal
    -   Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of \> 0.05 mV)
    -   Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria

-   `thalach` : maximum heart rate achieved during exercise

-   `output` : the doctor's diagnosis of whether the patient is at risk for a heart attack

    -   0 = not at risk of heart attack
    -   1 = at risk of heart attack

# Part Zero

```{r}
#| eval: false

ha <- read_csv(here::here("03-Classification", 
                          "Assignment", 
                          "data", 
                          "heart_attack.csv")
               )
```

Download the [`heart_attack.csv`](data/heart_attack.csv) and read in the data. Perform any data cleaning you believe is necessary.

::: callout-tip
# Setting Primary Target

You will find it helpful to reorder the `output` variable, so that the "at risk" group (e.g., level `1`) is the first level.

Here's some example code that you might find helpful:

```{r}
#| eval: false

ha <- ha %>%
  mutate(
    across(.cols = c(sex, cp, restecg), 
           .fns = ~as.factor(.x)
           ), 
    output = factor(output, levels = c(1, 0)
                    ) # make "at-risk" the primary target
  ) %>%
  drop_na(output)
```
:::

# Part One: Fitting Models

This section asks you to create a final best model for each of the model types studied this week. For each, you should:

-   Find the best model based on `roc.auc` for predicting the `output` variable.

-   Output a **confusion matrix**; that is, the counts of how many observations fell into each predicted class for each true class.

::: callout-tip
# Look over past code

Code is provided from lecture; alternatively, `conf_mat()` is a nice shortcut function for this task.)
:::

-   Report the (cross-validated!) `roc.auc` metric.

-   Fit the final model.

::: callout-caution
# Include All the Code!

As I expect your analysis to be reproducible, your assignment should keep a record of **every** model you fit during your exploration.
:::

#### Q1: KNN

::: callout-tip
# Tuning

You *should* include a discussion of your hyperparameter tuning steps in your write-up.
:::

#### Q2: Logistic Regression

#### Q3: LDA

#### Q4: QDA

# Part Two: Interpreting Models

#### Q5: Interpretation

Which predictors were most important to predicting heart attack risk? Were these predictors consistent across the different types of models you fit?

#### Q6: ROC Curve

Plot the ROC for your favorite model from Q1-4.

::: callout-tip
# Making an ROC Curve

Here's some code to help you plot your favorite model's ROC:

```{r}
#| eval: false
#| echo: true

ha %>%
  mutate(
    preds = predict(model_final, ha, type = "prob")$.pred_1
  ) %>%
  roc_curve(
    truth = output,
    preds
  ) %>%
  autoplot()
```
:::

# Part Three: Metrics

Consider the following metrics:

-   **True Positive Rate** or **Sensitivity** = Of the observations that are truly Class A, how many were predicted to be Class A?

-   **Precision** or **Positive Predictive Value** = Of all the observations classified as Class A, how many of them were truly from Class A?

-   **True Negative Rate** or **Specificity** = Of all the observations classified as NOT Class A, how many were truly NOT Class A?

Compute each of these metrics (cross-validated) for your four models in Part One.

::: callout-tip
# Specifying Metrics

You can specify which metrics you want to calculate as follows:

```{r}
#| eval: false

my_workflow %>%
  fit_resamples(cvs,
                metrics = metric_set(accuracy, roc_auc)) %>%
  collect_metrics()
```

For a list of all available metrics here: <https://yardstick.tidymodels.org/articles/metric-types.html>
:::

# Part Four: Validation

Before sharing the dataset with you, I set aside a random 10% of the observations to serve as a final validation set.

Download the [`heart_attack_validation.csv`](daheart_attack_validation.csv) and read in the data. Remember to clean these data the **same** way you cleaned the training data.

```{r}
#| eval: false
#| echo: false

ha_validation <- read_csv(here::here("03-Classification", 
                          "Assignment", 
                          "data", 
                          "heart_attack_validation.csv")
               )
```

```{r}
#| eval: false
#| echo: false

ha_validation <- ha_validation %>%
  mutate(
    across(.cols = c(sex, cp, restecg), 
           .fns = ~as.factor(.x)
           ), 
    output = factor(output, levels = c(1, 0)
                    ) # make "at-risk" the primary target
  ) %>%
  drop_na(output)
```

Use each of your final models in Part One Q1-4 to:

-   predict the `output` variable in the validation dataset
-   output a confusion matrix
-   report the `roc.auc`, the `precision`, and the `recall`

Compare these values to the cross-validated estimates you reported in Part One. Did our measure of model success turn out to be approximately correct for the validation data?

# Part Four: Discussion

Suppose you have been hired by a hospital to create classification models for heart attack risk.

The following questions give a possible scenario for why the hospital is interested in these models. For each one, discuss:

-   Which metric(s) you would use for model selection and why.

-   Which of your final models (Part One Q1-4) you would recommend to the hospital, and why.

#### Q1

The hospital faces severe lawsuits if they deem a patient to be low risk, and that patient later experiences a heart attack.

#### Q2

The hospital is overfull, and wants to only use bed space for patients most in need of monitoring due to heart attack risk.

#### Q3

The hospital is studying root causes of heart attacks, and would like to understand which biological measures are associated with heart attack risk.

#### Q4

The hospital is training a new batch of doctors, and they would like to compare the diagnoses of these doctors to the predictions given by the algorithm to measure the ability of new doctors to diagnose patients.
