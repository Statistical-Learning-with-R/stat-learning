---
title: "Dimension Reduction & Clustering"
format: 
  html: 
    self-contained: true
    theme: minty
    fontsize: 1em
    mainfont: sans-serif
    number-sections: true
    number-depth: 2
    code-block-bg: "#76b5c5"
    highlight-style: monochrome
editor: source
execute: 
  echo: true
  eval: false
  include: false
---

This week we will have **two** topics we are focusing on---dimension reduction and clustering. We will break these topics into two installments, first covering dimension reduction (since it is related to last week's reading on regularization) and then moving to clustering. 

# Dimension Reduction -- PCA

## Textbook Reading

üìñ [**Required Reading:** *ISLR -- Chapter 6, Section 6.3* AND *Chapter 12, Section 12.2*](https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf)

::: callout-warning
# Dimension Reduction Methods Across Two Chapters

Read pages 252 through 261 **and** pages 496 through 508! 
:::

## Reading Guide -- Due Monday, October 30 at 2:10pm

üìù [Download the Word Document](reading-guide/week-6a.docx)

## Tutorial Videos

Here's a helpful video which explains how PCA works: <https://youtu.be/FgakZw6K1QQ?si=n9f_d4lM1AGjFNg_>

# Clustering

## Textbook Reading

üìñ [**Required Reading:** *ISLR -- Chapter 12, Section 12.4*](https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf)

::: callout-warning
# Read pages 514 through 530! 
:::

## Concept Quiz 

**Question 1** -- PCA and clustering are both examples of what type of method?

- supervised learning
- unsupervised learning

**Question 2** -- The K-means clustering procedure ensures that each observations belongs to 
[at most one / at least one] cluster, the clusters are [overlapping / non-overlapping], and the [within-cluster / between-cluster] variance is as small as possible. 

**Question 3** -- In the first step of the K-means algorithm, each observation is [assigned to the cluster with the closest mean / randomly assigned to a cluster]. K-means [is / is not] sensitive to the initial assignment of observations to clusters, meaning the clustering results [do / do not] vary based on the initial assignment of observations.  

**Question 4** -- The number of leaves in a dendrogram is always equal to the sample size. 

- True
- False

**Question 5** -- On the vertical axis of a dendrogram, a value of 1 represents [n cuts / no cuts], where observations are in [one / n] cluster(s). A value of 0 represents [n cuts / no cuts], where observations are in [one / n] cluster(s).  

**Question 6** -- What linkages are the most popular among statisticians (in hierarchical clustering)? **Select all that apply**

- average
- centroid
- complete
- single

**Question 7** -- The results of clustering should be viewed as [a final model for confirming hypotheses / a starting point for generating scientific hypotheses]. 


## Tutorial Videos

Here's a helpful video which explains how K-means clustering works:
<https://youtu.be/4b5d3muPQmA?si=wZbMLsFq7UAO9RKe>

Here's a helpful video which explains how hierarchical clustering works:
<https://youtu.be/7xHsRkOdVwo?si=8q8X1fjpiW5BiBCQ>
