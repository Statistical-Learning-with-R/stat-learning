---
title: "Welcome to Stat 551!"
format: 
  revealjs:
    theme: [night, style.scss]
    embed-resources: true
    slide-number: false
    scrollable: true
editor: visual
execute: 
  echo: false
  message: false
  warning: false
---

::: larger
Warm-up (2-3 minutes)
:::

. . .

:::: large
::: {style="color: #b76352;"}
1.  What is something that you are good at doing?

2.  How did you get good at the thing you are good at doing?
:::
::::

## 

::: larger
About Me...
:::

* I am unfortunately overeducated.
    + Ph.D. in Statistics from UNC Chapel Hill
    + B.S. in Statistics from Harvard

* I love all things R.
    + `flair` and `flourish` packages
    + `tidyclust` R package
    + "paRticles" blog

* My methodological research is in clustering/unsupervised learning.
    + "Differential Correlation Mining" methods
    + Resampling metrics for correlation

* My applied research (right now) is varied.
    + Social networks in Poland
    + Chemical properties of vineyard soil



## 

::: larger
Some things I like...
:::

::: {.flex style="display: flex; flex-wrap: wrap; gap: 10px;"}

![](./images/K-87-01.jpg){.tile style="max-width: 30%; height: auto;"}
![](./images/backpacking.jpg){.tile style="max-width: 30%; height: auto;"}

![](./images/catan.jpeg){.tile style="max-width: 30%; height: auto;"}


![](./images/derby.jpg){.tile style="max-width: 30%; height: auto;"}

![](./images/21p.jpeg){.tile style="max-width: 80%; height: auto;"}

![](./images/SanJoseSharksLogo.svg){.tile style="max-width: 80%; height: auto;"}


![](./images/fcb.png){.tile style="max-width: 30%; height: auto;"}



:::

# What is Statistical Learning?

## Modeling

Every analysis we will do assumes a structure like:

::: centered
[**output** =]{.large}[f]{style="color: #abdbe3; font-size: 1.25em"}(**input**) + (noise)
:::

. . .

</br>

...or, if you prefer...

::: centered
[**response variable(s)** =]{.midi}[f]{style="color: #abdbe3; font-size: 1.25em"}(**explanatory variables**) + (noise)
:::

. . .

::: centered
[**dependent variable(s)** =]{.midi}[f]{style="color: #abdbe3; font-size: 1.25em"}(**independent variables**) + (noise)
:::

. . .

::: centered
[**target** =]{.midi}[f]{style="color: #abdbe3; font-size: 1.25em"}(**predictors**) + (noise)
:::

# Modeling

In any case: we are trying to reconstruct information in **data**, and we are hindered by **random noise**.

. . .

</br>

:::::::: columns
:::: {.column width="40%"}
The function [f]{style="color: #abdbe3; font-size: 1.5em"} might be very simple...

::: large
Y = X + $\epsilon$
:::
::::

::: {.column width="5%"}
:::

:::: {.column width="55%"}
::: fragment
...or very complex

$z_i = b_o + b_1 x_i$

$q_i = \frac{1}{1 + exp(-z_i)}$

$y_i \sim Bern(q_i)$
:::
::::
::::::::

# This or That?

## Statistical Learning vs. Machine Learning

You will often hear people refer to **machine learning** in reference to the topics in this class.

. . .

</br>

[My opinion:]{.larger}

::: midi
**Statistical learning** is more concerned with the *model structure*, *interpretation of estimates*, and *understanding error*.
:::

. . .

::: midi
**Machine learning** is more concerned with *model implementation* and *computational demands*.
:::

## Quantitative (numeric) vs. qualitative (categorical)

Often, the nature of our models will differ depending on the types of data involved!

</br>

:::::: columns
::: {.column width="45%"}
[**regression**]{style="color: #e28743; font-size: 1.25em"}

the response variables are *quantitative*
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
[**classification**]{style="color: #76b5c5; font-size: 1.25em"}

the response variables are *categorical*
:::
::::::

## Supervised vs. Unsupervised

</br>

**supervised** learning: our data includes observations of the output variable

> What drug treatments are associated with better disease outcomes?

. . .

**unsupervised** learning: our data does NOT include any observations of the output variable

> What social groups already exist among the Stat 551 students?

# Prediction vs. Inference

So, why do we care about estimating [f]{style="color: #abdbe3; font-size: 1.25em"}?

. . .

</br>

::: midi
**prediction**: We are trying to use future **inputs** to guess about future **outputs**.

> Which articles are you most likely to read?
:::

. . .

::: midi
**inference**: We are trying to tell a story about the **relationship** between variables.

> Which genes are more activated when breast cancer is present?
:::

# What do we need to learn?

## Why not just "plug and chug"?

It is important to think carefully about:

::: incremental
-   **Assumptions:** What do various models assume to be true about the data structure? Are these justified?

-   **Interpretations:** What can we learn by estimating [f]{style="color: #abdbe3; font-size: 1.25em"} for a particular model? Is that information what we are looking for?

-   **Estimation:** How is each [f]{style="color: #abdbe3; font-size: 1.25em"} being approximated? Will this be a close approximation?

-   **Usage:** What are we going to do once we estimate [f]{style="color: #abdbe3; font-size: 1.25em"}? Do certain models lend themselves better than others?
:::

## Estimation

If we are doing [prediction]{.underline}, we mostly don't care about *assumptions*.

. . .

The "best" model is the model that predicts most accurately.

. . .

But: What measure of *accuracy* do we prioritize?

. . .

</br>

If we are doing [inference]{.underline}, we care a lot about *assumptions*.

. . .

The "best" model is the one that matches the truth.

. . .

But: What the heck is the *truth*???

# In this Class

You will learn:

-   To apply many different models to real data using `tidymodels` in **R**.

-   To interpret the output of these model estimates

-   To use *cross-validation* to compare models

-   To explain the general structure and philosophy behind each model

-   To select an appropriate "best" model for a data analysis, and make a well-reasoned argument for your choice.
