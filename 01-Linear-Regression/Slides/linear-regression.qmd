---
title: "Linear Regression Review"
format: 
  revealjs:
    theme: [night, style.scss]
    embed-resources: true
    slide-number: false
embed-resources: true

editor: source
---

# Modeling

Recall:  We are assuming that 

::: {.centered}

**output** =  [f]{style="color: #e28743; font-size: 1.25em"}(**input**) + (noise)
:::
</br>

and we would like to estimate [f]{style="color: #e28743; font-size: 1.25em"}.


# Linear Model


$$Y = \beta_0 + \beta_1 X + \epsilon$$


Goal:  Use observations $(x_1, y_1), ..., (x_n, y_n)$ to estimate $\beta_0$ and $\beta_1$.


# Measures of success

What is the "best" choice of $\widehat{\beta}_0$ and $\widehat{\beta}_1$?

::: columns
::: {.column width="30%"}
::: {.fragment .fade-in-then-out}
The ones that are **statistically most justified**, under certain assumptions about $Y$ and $X$?
:::
:::

::: {.column width="3%"}
:::

::: {.column width="30%"}
::: {.fragment .fade-in-then-out}
The ones that minimize the prediction error?

- $|\widehat{y}_i - y_i|$?
- $(\widehat{y}_i - y_i)^2$?
- $(\widehat{y}_i - y_i)^4$?
:::
:::

::: {.column width="3%"}
:::

::: {.column width="30%"}
::: {.fragment .fade-in-then-out}
The ones that minimize the prediction error *on new information*?

- $|y_{new} - \widehat{y}_{new}|$?
- $(y_{new} - \widehat{y}_{new})^2$?
- $(y_{new} - \widehat{y}_{new})^4$?
:::
:::
:::

# Maximum Likelihood Estimate (MLE)


Let's assume $X$ is **Normally distributed** with some mean and variance.

Let's assume that $Y$ *given* $X$ is **Normally distributed** with a mean of $\beta_0 + \beta_1 X$ and some variance.

::: incremental
::: {.smaller}
* Based on our data, what do we think are the mean and variance of $X$?

* Based on our data, what do we think are the mean and variance of $Y$?

* Based on our data, what is our *best guess* about $\beta_0$ and $\beta_1$?
:::
:::

# MSE/SSE/RSE/RMSE

::: {.centered}
The **residual** of a model is how much you "missed" by:

$y_i - \widehat{y_i}$
:::

</br>

. . .

::: columns
::: {.column width="40%"}
The **squared residual**, or **squared error** is that squared:

$(y_i - \widehat{y_i})^2$

:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
::: {.fragment}
The **sum of squared error (SSE)** is all those added up:

$\sum_{i = 1}^n (y_i - \widehat{y_i})^2$
:::

</br>

::: {.fragment}
:::{.smaller}
This is also called the **residual squared error (RSE)** or **residual sum of squares (RSS)**. *Yes, those are all the same thing.  Statistics is silly sometimes.*
:::
:::
:::
:::


# MSE/SSE/RSE/RMSE


The **mean squared error (MSE)** is all those added up and then averaged:

::: {.centered}
$\sum_{i = 1}^n \frac{1}{n} (y_i - \widehat{y_i})^2$
:::

. . .

</br> 

The **root mean squared error (RMSE)** is the square root of the MSE:

::: {.centered}
$\sqrt{\sum_{i = 1}^n \frac{1}{n} (y_i - \widehat{y_i})^2}$
:::


# MSE/SSE/RSE/RMSE

**What's the point of all this?**

. . .

If we decide the "best" $\beta_0$ and $\beta_1$ are the ones that minimize the **MSE**...

. . .

that's exactly the same as minimizing the **RMSE**, the **RSS**, the **SSE**, the **RSE**!

. . .

These are all measuring "how far are our predictions from the truth, in squared distance?"!

. . .

This is **not** the same as "absolute" error ($|y_i - \widehat{y_i}|$)


# Data Science in the Wild

Before any modeling analysis, you have to decide what your definition of the [best model]{.underline} is!

# Linear model estimates

For linear models (but not *every* model!) the "best" model according to the **MLE** and the "best" model according to the **MSE** agree!

. . .

Okay, so how do we calculate $\beta_0$ and $\beta_1$?

# Make the computer do it!

...well technically R! 

# Get the idea, not the math

::: columns
::: {.column width="45%"}
**What you DON'T need to know:**

::: {.smaller}
* Mathematical equations used to compute $\beta_0$ and $\beta_1$

* Statistical properties of $\beta_0$ and $\beta_1$

* How the computer does these calculations
:::
:::

::: {.column width="5%"}
:::

::: {.column width="47%"}
**What you DO need to know:**

:::{.smaller}
* How to **make** a computer do the calculations

* Which measure of model success lead to this estimation

* How to interpret the results
:::
:::
:::

# Let's get started.
