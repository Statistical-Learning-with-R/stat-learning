---
title: "Assignment 1: Linear Models"
author: "Solutions by Dr. Theobold"
format: html
embed-resources: true
editor: source
---

```{r}
#| label: packages
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

# Step 1: Download the Data

The dataset we will study for this assignment contains information about health insurance costs for individuals with no dependents (children) in the United States. The information contained in the data is:

-   Age of primary beneficiary

-   Biological sex of primary beneficiary (recorded as gender)

-   Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight ($\frac{kg}{m^2}$) using the ratio of height to weight, ideally 18.5 to 24.9

-   Whether the beneficiary smokes

-   The beneficiary's residential area in the US, northeast, southeast, southwest, northwest.

-   Individual medical costs billed by health insurance

# Step 2: Explore the Data

1.  Read in the dataset, and display some summaries of the data.

```{r}
#| label: data-summary
#| message: false

ins <- read_csv(
  here::here(
    "01-Linear-Regression", 
    "Assignment", 
    "data", 
    "insurance_costs_1.csv"
    )
  )
```

2.  Fix any concerns you have about the data.

```{r}
#| label: change-data-type

ins <- ins %>%
  mutate(
    across(.cols = where(is.character), 
           .fns = ~ as.factor(.x)
           )
  )
```

3.  Make up to three plots comparing the response variable (`charges`) to one of the predictor variables (e.g., `age`, `smoker`, `sex`, `bmi`, `region`). Briefly discuss what you notice in each plot (1-2 sentences per plot!).

```{r}
#| label: scatterplot
ins %>%
  ggplot(mapping = aes(x = age, y = charges)) +
  geom_point() + 
  scale_y_continuous(labels = label_dollar()) +
  labs(x = "Age of Client", 
       title = "Cost of Medical Charges in US Healthcare",
       y = "")
```

Based on the plot above, it appears that as someone's age increases their medical charges also tends to increase (as one would expect). Interestingly, there appears to be three "groups" or lines within this relationship:

1. a tightly clustered group near the bottom of the plot whose medical charges start around about $0
2. a group in the middle, with moderate variability, whose medical charges start around $20,000
3. a group on the top, also with moderate variability, whose medical charges start around $40,000

```{r}
#| label: region-smoker
#| message: false

library(ggridges)
library(scales)

ins %>%
  ggplot(mapping = aes(y = region, x = charges, fill = smoker)) +
  geom_density_ridges(alpha = 0.5) + 
  scale_x_continuous(labels = label_dollar()) +
  labs(x = "Insurance Costs", 
       title = "Medical Costs by Region of the US", 
       fill = "Smoker", 
       y = "")
```

The plot suggests the distributions of medical charges for non-smokers (pink curves) don't vary that much between the regions. However, the distributions of charges for smokers does seem to vary between regions, with the Southwest having the largest spread and multiple modes. 

```{r}
#| label: region-sex
#| message: false

ins %>%
  ggplot(mapping = aes(y = region, x = charges, fill = sex)) +
  geom_density_ridges(alpha = 0.5) + 
  scale_x_continuous(labels = label_dollar()) +
  labs(x = "Insurance Costs", 
       title = "Medical Costs by Region of the US", 
       fill = "Sex", 
       y = "")
```

The plot suggest the distributions of medical charges for different sexes don't vary that much between the regions, as most of the density curves are entirely overlapping. Indeed, the peak medical charges for females in the Southwest and Northeast are slightly larger than for males, but they occur at the same locations. 

# Step 3: Create (Simple) Models of the Data

4.  Fit a simple linear model to predict the insurance charges from the beneficiary's age.

```{r}
#| label: linear-regression

lin_reg_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

ins_lm_age <- lin_reg_spec %>%
  fit(charges ~ age, data = ins) 

tidy(ins_lm_age)
```

5.  Interpret the coefficient estimates.

For each additional year in a person's age, the charges increase by $229 on average.

For a person that is 0 years old, the average charge is $3611. While this might not seem like extrapolation, since someone incurs medical charges when they are born, these medical charges are not billed to the child but to the parents. Based on the table below, the youngest observation in our dataset is 18 years old. 

```{r}
summarise(ins, 
          min_age = min(age), 
          max_age = max(age)
          )
```

6.  Discuss the model fit, specifically the p-value associated with `age` and the model's $R^2$.

```{r}
#| label: model-summary

glance(ins_lm_age)
```

The p-value of the model is basically 0. That means there is strong evidence of a linear relationship between the age and the amount of healthcare expenses.

The r-squared value is 0.09938. This means about 9.9% of the variance in charges can be explained by the linear regression model including `age` as a predictor.

7.  Fit a model that also incorporates the variable `sex`. Specifically, `sex` should be included both as a main effect and in an interaction with `age`.

```{r}
#| label: adding-sex

ins_lm_fit_age_sex <- lin_reg_spec %>%
  fit(charges ~ age * sex, data = ins) 
```

8.  Provide interpretations for each of the coefficient estimates.

```{r}
tidy(ins_lm_fit_age_sex)
```

`(Intercept)`: The insurance charge for someone sexed as femal who is 0 years old is estimated to be $2,763.

`age`: Among women, the insurance charges increase by $243 on average for 1 year increase in age.

`sexmale`: Insurance charges are on average $1805 higher for men than for women (across all ages).

`age:sexmale`: Among men, the insurance charges increase by $213 (243 - 30) on average for every 1 year increase in age.

9.  Does it seem that the relationship between `age` and `cost` differs based on someone's `sex`? Why or why not?

The p-value of the slope for age is near 0, but the p-value for the adjustments due to sex are high. This suggests that the relationship between someone's age and their insurance prices may not differ by a person's designated sex.

10. How much additional variation in `cost` were we able to explain by adding `sex` into our model?

```{r}
glance(ins_lm_fit_age_sex)
```

The r-squared value is 0.1006. This means 10.06% of the variance in charges is explained by sex and age. This isn't a large increase, since we started at 9.9%, so we gained less than 1% from where we started.

11. Now fit a model that does not include `sex`, but does include `smoker`. Specifically, `smoker` should be included both as a main effect and in an interaction with `age`.

```{r}
ins_lm_fit_age_smoke <- lin_reg_spec %>%
  fit(charges ~ age * smoker, ins) 
```

12. Which model (`sex` or `smoker`) do you think better fits the data? Justify your answer by calculating the MSE for each model, and also by comparing R-squared values.

```{r}
ins <- ins %>% 
  mutate(
    predictions_sex = predict(ins_lm_fit_age_sex, new_data = ins)$.pred,
    predictions_smoke = predict(ins_lm_fit_age_smoke, new_data = ins)$.pred
  )
                
ins %>%
  rmse(truth = charges,
      estimate = predictions_sex)

ins %>%
  rmse(truth = charges,
      estimate = predictions_smoke)
```

Based on the R-squared value being much higher, and the RMSE being much lower, the model with `smoker` is MUCH better.

# Step 4: Create More Complex Models of the Data

Now let's consider including multiple *quantitative* predictors.

13. Fit a model that uses `age` and `bmi` as predictors.

```{r}
ins_lm_fit_age_bmi <- lin_reg_spec %>%
  fit(charges ~ age + bmi, ins) 
```

14.  Provide interpretations for each of the coefficient estimates.

```{r}
tidy(ins_lm_fit_age_bmi)
```

`(Intercept)`: For someone with a BMI of 0 and who is 0 years old, we estimate they incur -$4,628 in medical expenses.

`age`: Insurance charges increase by $216 on average for every 1 year increase in age.

`bmi`: Insurance charges increase by $283 on average for every 1 point increase in BMI. 

15. How does the R-squared compare to the model with `smoker`?

```{r}
glance(ins_lm_fit_age_bmi)
```

12% of the variance in charges can be explained by year and age.

16. How does the RMSE compare to the model with `smoker`?

```{r}
ins %>% 
  mutate(
    predictions_age_bmi = predict(ins_lm_fit_age_bmi, new_data = ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions_age_bmi
  )
```

The RMSE (11,126) is higher than in the model with `smoker` (5,804), and barely lower than the model with `sex` (11,250).

17. Looking at the plot of `age` versus `charges` it seems like the relationship may not be linear! Fit a model that uses `age` and `age^2` as predictors (your model should not include `bmi`).

```{r}
ins_poly_2 <- lin_reg_spec %>%
  fit(charges ~ poly(age, 2), data = ins) 
```

18. How do the RMSE and R-squared compare to the model when we just used `age` (Step 3, Question 4)?

```{r}
glance(ins_poly_2)

ins %>% 
  mutate(
    predictions = predict(ins_poly_2, ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions
  )
```

The R-squared (0.0996) and RMSE (11,257) are almost identical to when we just used `age` ($R^2 = 0.0994$, RMSE = 11,258).

19. Let's get a little wigglier! Fit a polynomial model of degree 4. How do the MSE and R-squared compare to the model in (Step 3, Question 4)?

```{r}
ins_poly_4 <- lin_reg_spec %>%
  fit(charges ~ poly(age, 4), ins) 

glance(ins_poly_4)

ins %>% 
  mutate(
    predictions = predict(ins_poly_4, ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions
  )
```

The R-squared (0.108) and RMSE (11,205) are slightly better than when we just used `age` ($R^2 = 0.0994$, RMSE = 11,258).

20. According to the MSE and R-squared, which is the best model? Do you agree that this is indeed the "best" model? Why or why not?

Based on the R-squared and RMSE, the best model is the 4-degree polynomial. However, this is a bad way to choose; models with more flexibility will *always* have a better R-squared and RMSE, but they are in danger of overfitting to the data. So, I believe the model with `smoker` and `age` is the best model. 

21. Plot the predictions from the model you believe is the best as a **line** plot on top of the scatterplot of your original data.

```{r}
ins %>% 
  mutate(
    predictions = predict(ins_lm_fit_age_smoke, new_data = ins)$.pred
  ) %>%
  ggplot() +
  geom_point(mapping = aes(x = age, y = charges)) +
  geom_smooth(mapping = aes(x = age, y = predictions, color = smoker)) + 
  scale_y_continuous(labels = label_dollar()) +
  labs(x = "Age of Client", 
       title = "Cost of Medical Charges in US Healthcare",
       y = "", 
       color = "Smoking Status")

```

# Step 5: Incorporate New Data

Great news! We've managed to collect data about the insurance costs for a few more individuals. You can find the new dataset [here](data/insurance_costs_2.csv).

Consider the following possible models:

-   Only `age` as a predictor.

-   `age` and `bmi` as a predictor.

-   `age`, `bmi`, and `smoker` as predictors (no interaction terms)

-   `age`, and `bmi`, with both quantitative variables having an interaction term with `smoker` (i.e. the formula `~ (age + bmi):smoker`)

-   `age`, `bmi`, and `smoker`as predictors, with both quantitative variables having an interaction term with `smoker` (i.e. the formula `~ (age + bmi)*smoker`)

22. For each model, *fit* the model on the **original data**.

```{r}
#| message: false

ins_new <- read_csv(
  here::here(
    "01-Linear-Regression", 
    "Assignment", 
    "data", 
    "insurance_costs_2.csv"
    )
  )

fit_1 <- lin_reg_spec %>%
  fit(charges ~ age, data = ins)

fit_2 <- lin_reg_spec %>%
  fit(charges ~ age + bmi, data = ins)

fit_3 <- lin_reg_spec %>%
  fit(charges ~ age + bmi + smoker, data = ins)

fit_4 <- lin_reg_spec %>%
  fit(charges ~ (age + bmi):smoker, data = ins)

fit_5 <- lin_reg_spec %>%
  fit(charges ~ (age + bmi)*smoker, data = ins)
```

23. For each model, use the fitted model to *predict* on the **new data**.

```{r}
ins_new <- ins_new %>%
  mutate(
    preds_1 = predict(fit_1, ins_new)$.pred,
    preds_2 = predict(fit_2, ins_new)$.pred,
    preds_3 = predict(fit_3, ins_new)$.pred,
    preds_4 = predict(fit_4, ins_new)$.pred,
    preds_5 = predict(fit_5, ins_new)$.pred,
  )
```

::: {.callout-tip}
# Repeated Code

Yes, we are technically repeating the `predict()` function five times, but it is surprisingly difficult to reduce the duplication in this code! So, I am leaving it be.
:::

24. Report the MSE for each model's **new** predictions. Based on this, which is the best model to use?

```{r}

ins_new %>% 
  pivot_longer(cols = starts_with("preds"), 
               names_to = "model", 
               values_to = "prediction") %>% 
  group_by(model) %>% 
  rmse(truth = charges, estimate = prediction)
```

The last model had the best MSE, although the second to last was close. I'm going to choose `fit_4` since it has fewer coefficient estimates. 

25. Make a plot showing the residuals of your final chosen model.

```{r}
ins_new %>% 
  mutate(
    resids = charges - preds_4
  ) %>%
  ggplot() +
  geom_point(aes(x = age, y = resids)) + 
  scale_y_continuous(labels = label_dollar()) +
  labs(x = "Age", 
       y = "Residual") 
```
