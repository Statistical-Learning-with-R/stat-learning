---
title: "Assignment 1: Linear Models"
author: "Due Monday, October 2 at 5pm"
format: html
embed-resources: true
editor: source
---

```{r}
#| label: packages
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
```

# Step 1: Download the Data

The dataset we will study for this assignment contains information about health insurance costs for individuals with no dependents (children) in the United States. The information contained in the data is:

-   Age of primary beneficiary

-   Biological sex of primary beneficiary (recorded as gender)

-   Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight ($\frac{kg}{m^2}$) using the ratio of height to weight, ideally 18.5 to 24.9

-   Whether the beneficiary smokes

-   The beneficiary's residential area in the US, northeast, southeast, southwest, northwest.

-   Individual medical costs billed by health insurance

1.  Read in the dataset, and display some summaries of the data.

```{r}
#| label: data-summary
#| echo: fenced

ins <- read_csv(
  here::here(
    "01-Linear-Regression", 
    "Assignment", 
    "data", 
    "insurance_costs_1.csv"
    )
  )

summary(ins)

ins %>% count(smoker)
ins %>% count(region)
ins %>% count(sex)
```

2.  Fix any concerns you have about the data.

```{r}
#| label: change-data-type

ins <- ins %>%
  mutate(
    smoker = factor(smoker),
    sex = factor(sex),
    region = factor(region)
  )
```

3.  Make up to three plots comparing the response variable (`charges`) to one of the predictor variables. Briefly discuss each plot.

```{r}
#| label: scatterplot
ins %>%
  ggplot(mapping = aes(x = age, y = charges)) +
  geom_point() + 
  scale_y_continuous(labels = label_dollar()) +
  labs(x = "Age of Client", 
       title = "Cost of Medical Charges in US Healthcare",
       y = "")
```

```{r}
#| label: region-smoker

library(ggridges)
library(scales)

ins %>%
  ggplot(mapping = aes(y = region, x = charges, fill = smoker)) +
  geom_density_ridges(alpha = 0.5) + 
  scale_x_continuous(labels = label_dollar()) +
  labs(x = "Insurance Costs", 
       title = "Medical Costs by Region of the US", 
       fill = "Smoker", 
       y = "")
```

```{r}
#| label: region-sex
ins %>%
  ggplot(mapping = aes(y = region, x = charges, fill = sex)) +
  geom_density_ridges(alpha = 0.5) + 
  scale_x_continuous(labels = label_dollar()) +
  labs(x = "Insurance Costs", 
       title = "Medical Costs by Region of the US", 
       fill = "Sex", 
       y = "")
```

## Part Two: Simple Linear Models

4.  Fit a simple linear model to predict the insurance charges from the beneficiary's age.

```{r}
#| label: linear-regression

lin_reg_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

ins_lm_age <- lin_reg_spec %>%
  fit(charges ~ age, data = ins) 

tidy(ins_lm_age)
```

5.  Interpret the coefficient estimates.

For a person that is 0 years old, the average charge is \$3611.

For each additional year in a person's age, the charges increase by \$229 on average.

6.  Discuss the model fit, specifically the p-value associated with `age` and the model's $R^2$.

```{r}
#| label: model-summary

glance(ins_lm_age)
```

The p-value of the model is basically 0. That means there is probably a relationship between the age and the amount of healthcare expenses.

The r-squared value is 0.09938. This means about 9.9% of the variance in charges can be explained by the linear regression model including `age` as a predictor.

7.  Fit a model that also incorporates the variable `sex`.

```{r}
#| label: adding-sex

ins_lm_fit_age_sex <- lin_reg_spec %>%
  fit(charges ~ age*sex, data = ins) 
```

8.  Provide interpretations for each of the coefficient estimates.

```{r}
tidy(ins_lm_fit_age_sex)
```

`sexmale`: Insurance charges are on average \$1805 higher for men than for women.

`age`: Among women, the insurance charges increase by \$243 on average for every year of age.

`age:sexmale`: Among men, the insurance charges increase by (243 - 30 = ) \$213 on average for every year of age.

9.  Does it seem that the relationship between `age` and `cost` differs based on someone's `sex`? Why or why not?

The p-value of the slope for age is near 0, but the p-value for the adjustments due to sex are high. This suggests that there may not be a relationship between a person's designated sex and their insurance prices.

10.  How much additional variation in `cost` were we able to explain by adding `sex` into our model?

```{r}
glance(ins_lm_fit_age_sex)
```

The r-squared value is 0.1006. This means 10.06% of the variance in charges is explained by sex and age. This isn't a large increase, since we started at 9.9%, so we gained less than 1% from where we started.

11.  Now fit a model that does not include `sex`, but does include `smoker`.

```{r, version = "answer_key"}
ins_lm_fit_age_smoke <- lin_reg_spec %>%
  fit(charges ~ age*smoker, ins) 
```

12.  Which model (`sex` or `smoker`) do you think better fits the data? Justify your answer by calculating the MSE for each model, and also by comparing R-squared values.

```{r}
ins <- ins %>% 
  mutate(
    predictions_sex = predict(ins_lm_fit_age_sex, new_data = ins)$.pred,
    predictions_smoke = predict(ins_lm_fit_age_smoke, new_data = ins)$.pred
  )
                
ins %>%
  rmse(truth = charges,
      estimate = predictions_sex)

ins %>%
  rmse(truth = charges,
      estimate = predictions_smoke)
```

Based on the R-squared value being much higher, and the RMSE being much lower, the model with `smoker` is MUCH better.

## Part Three: Multiple Linear Models

Now let's consider including multiple *quantitative* predictors.

13.  Fit a model that uses `age` and `bmi` as predictors.

::: callout-caution
# No interaction

Do not include an interaction term between `age` and `bmi`!
:::

14.  Provide interpretations for each of the coefficient estimates.

```{r, version = "answer_key"}
ins_lm_fit_age_bmi <- lin_reg_spec %>%
  fit(charges ~ age + bmi, ins) 

tidy(ins_lm_fit_age_bmi)
```

Insurance charges increase by $216 on average for every year of age.

Insurance charges increase by $283 on average for every point on the bmi scale.

15.  How does the R-squared compare to the model with `smoker`? 

```{r}
glance(ins_lm_fit_age_bmi)
```

12% of the variance in charges can be explained by year and age.

16. How does the RMSE compare to the model with `smoker`?

::: {.callout-tip}
# Calculate RMSE

Look back at this week's activity to remember how we calculated the RMSE of a model!
:::

```{r}
ins %>% 
  mutate(
    predictions_age_bmi = predict(ins_lm_fit_age_bmi, new_data = ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions_age_bmi
  )
```

The RMSE (11,126) is higher than in the model with `smoker` (5,804), and barely lower than the model with `sex` (11,250).

17.  Looking at the plot of `age` versus `charges` it seems like the relationship may not be linear! Fit a model that uses `age` and `age^2` as predictors (your model should not include `bmi`).

::: {.callout-hint} 
# Fitting a Polynomial

You can fit **both** the linear and quadratic terms using the following formula:

```{r}
#| label: polynomial-example
#| eval: false
charges ~ poly(age, 2)
```
:::

```{r}
ins_poly_2 <- lin_reg_spec %>%
  fit(charges ~ poly(age, 2), data = ins) 
```

18.  How do the RMSE and R-squared compare to the model when we just used `age` (Step 3, Question 4)?

```{r}
glance(ins_poly_2)

ins %>% 
  mutate(
    predictions = predict(ins_poly_2, ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions
  )
```

The R-squared (0.0996) and RMSE (11,257) are almost identical to when we just used `age` ($R^2 = 0.0994$, RMSE = 11,258).

19.  Let's get a little wigglier! Fit a polynomial model of degree 4. How do the RMSE and R-squared compare to the model when we just used `age` (Step 3, Question 4)?

```{r, version = "answer_key"}
ins_poly_4 <- lin_reg_spec %>%
  fit(charges ~ poly(age, 4), ins) 

glance(ins_poly_4)

ins %>% 
  mutate(
    predictions = predict(ins_poly_4, ins)$.pred
  ) %>%
  rmse(
    truth = charges,
    estimate = predictions
  )
```

The R-squared (0.108) and RMSE (11,205) are slightly better than when we just used `age` ($R^2 = 0.0994$, RMSE = 11,258).

20.  According to the MSE and R-squared, which is the best model? Do you agree that this is indeed the "best" model? Why or why not?

Based on the R-squared and RMSE, the best model is the 4-degree polynomial. However, this is a bad way to choose; models with more flexibility will *always* have a better R-squared and RMSE, but they are in danger of overfitting to the data.

21.  Plot the predictions from the model you believe is the best as a **line** plot on top of the scatterplot of your original data.

::: {.callout-warning}
# Axis labels

Don't forget your axis labels and units (where needed)!
:::

```{r}
ins %>% 
  mutate(
    predictions = predict(ins_poly_4, new_data = ins)$.pred
  ) %>%
  ggplot() +
  geom_point(mapping = aes(x = age, y = charges)) +
  geom_line(mapping = aes(x = age, y = predictions), 
            color = "blue") + 
  scale_y_continuous(labels = label_dollar()) +
  labs(x = "Age of Client", 
       title = "Cost of Medical Charges in US Healthcare",
       y = "")

```

## Part Four: New data

Great news! We've managed to collect data about the insurance costs for a few more individuals. You can find the new dataset [here](data/insurance_costs_2.csv)

Consider the following possible models:

-   Only `age` as a predictor.

-   `age` and `bmi` as a predictor.

-   `age`, `bmi`, and `smoker` as predictors (no interaction terms)

-   `age`, and `bmi`, with both quantitative variables having an interaction term with `smoker` (i.e. the formula `~ (age + bmi):smoker`)

-   `age`, `bmi`, and `smoker`as predictors, with both quantitative variables having an interaction term with `smoker` (i.e. `~ age*smoker + bmi*smoker`)

22. For each model, *fit* the model on the **original data**.

```{r}
ins_new <- read_csv(
  here::here(
    "01-Linear-Regression", 
    "Assignment", 
    "data", 
    "insurance_costs_2.csv"
    )
  )

fit_1 <- lin_reg_spec %>%
  fit(charges ~ age, data = ins)

fit_2 <- lin_reg_spec %>%
  fit(charges ~ age + bmi, data = ins)

fit_3 <- lin_reg_spec %>%
  fit(charges ~ age + bmi + smoker, data = ins)

fit_4 <- lin_reg_spec %>%
  fit(charges ~ (age + bmi):smoker, data = ins)

fit_5 <- lin_reg_spec %>%
  fit(charges ~ (age + bmi)*smoker, data = ins)
```

23. Now, use the fitted model to *predict* on the **new data**.

```{r}
ins_new <- ins_new %>%
  mutate(
    preds_1 = predict(fit_1, ins_new)$.pred,
    preds_2 = predict(fit_2, ins_new)$.pred,
    preds_3 = predict(fit_3, ins_new)$.pred,
    preds_4 = predict(fit_4, ins_new)$.pred,
    preds_5 = predict(fit_5, ins_new)$.pred,
  )
```

24. Report the MSE for each model's **new** predictions. Based on this, which is the best model to use?

```{r}

ins_new %>% 
  pivot_longer(cols = starts_with("preds"), 
               names_to = "model", 
               values_to = "prediction") %>% 
  group_by(model) %>% 
  rmse(truth = charges, estimate = prediction)
```

The last model had the best MSE, although the second to last was close. %%%

25. Make a plot showing the residuals of your final chosen model.

```{r}
ins_new %>% 
  mutate(
    resids = charges - preds_1 
  ) %>%
  ggplot() +
  geom_point(aes(x = age, y = resids))

```
