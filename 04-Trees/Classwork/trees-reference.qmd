---
title: "Decision Trees"
subtitle: "R Cheatsheet"
format: 
  html:
    embed-resources: true
editor: visual
execute: 
  eval: false
---

# Decision Trees

**Step 1**: Recipe

```{r}
cann_recipe <- recipe(Type ~ ., 
                     data = cann_clean) %>%
  step_rm(Strain, Effects, Flavor)
```

**Step 2**: Model

```{r}
tree_mod <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")
```

**Step 3**: Workflow

```{r}
tree_wflow <- workflow() %>%
  add_model(tree_mod) %>% 
  add_recipe(cann_recipe)
```

**Step 4**: CV & Fit Model

```{r}
cann_cvs <- vfold_cv(cann_clean, v = 5)

tree_fit <- tree_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall)
                )
```

**Step 5**: Inspect Metrics

```{r}
tree_fit %>% collect_metrics()
```

**Step 6**: Decide on a Model

**Step 7**: Fit the Model & Plot the Model

```{r}
tree_fitted <- tree_fit_1 %>% 
  extract_fit_parsnip()

rpart.plot(tree_fitted$fit)
```

# Tuning Trees

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)
```

```{r}
tree_mod <- decision_tree(cost_complexity = tune(),
                          tree_depth = tune(),
                          min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_model(tree_mod) %>% 
  add_recipe(cann_recipe)

tree_grid_search <-
  tune_grid(
    tree_wflow,
    resamples = cann_cvs,
    grid = tree_grid
  )

tuning_metrics <- tree_grid_search %>% 
  collect_metrics()
```

# Bagging Trees

**Step 1**: Recipe (same as before)

**Step 2**: Model

```{r}
bag_tree_mod <- bag_tree() %>%
  set_engine("rpart", times = 5) %>%
  set_mode("classification")
```

**Step 3**: Workflow

```{r}
bag_tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(bag_tree_spec)
```

**Step 4**: Fit Model 

```{r}
bag_tree_fit <- bag_tree_wflow %>%
  fit(cann)
```

**Step 5**: Inspect Models

```{r}
bag_tree_fit %>% 
  extract_fit_parsnip()
```

# Random Forests

**Step 0**: Select a Subset of Predictors

```{r}
cann_reduced <- cann %>%
  select(Type, 
         sample(5:65, size = 30)
         )
```

**Step 1**: Recipe on the Subset Data

```{r}
cann_recipe_2 <- recipe(Type ~ ., 
                     data = cann_reduced)
```

**Step 2**: Model

```{r}
rf_mod <- rand_forest(mtry = 30) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

**Step 3**: Workflow (same as before)

**Step 4**: Fit Model (same as before)

**Step 5**: Inspect Model (same as before)

# Tuning Forests

```{r}
mtry_grid <- grid_regular(mtry(c(1, 10)), 
                          levels = 5)
```

::: {.callout-tip}
# Choosing Variable Subsets

`mtry` allows you to control how many variables are considered (out of the total). The code above allows between 1 and 10 variables to be included.
:::

```{r}
rf_spec <- rand_forest(mtry = tune()) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_wflow <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(cann_recipe)

rf_fit <- rf_wflow %>%
  tune_grid(
    grid = mtry_grid,
    resamples = cann_cvs
    ) 

rf_fit %>% 
  collect_metrics()

```

::: {.callout-tip}
# Tuning Other Hyperparameters

You can also tune `min_n` and `trees` with random forests! 
:::
