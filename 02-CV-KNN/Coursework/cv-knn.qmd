---
title: "Cross Validation and K-Nearest Neighbors"
format: 
  html: 
    self-contained: true
    theme: minty
    fontsize: 1em
    mainfont: sans-serif
    number-sections: true
    number-depth: 2
    code-block-bg: "#76b5c5"
    highlight-style: monochrome
editor: source
execute: 
  echo: true
  eval: false
  include: false
---

# Cross Validation

The first chapter we will focus on discusses cross validation!

## Textbook Reading

üìñ **Required Reading:** *ISLR -- Chapter 5 Resampling Methods*

::: callout-warning
# Don't read the sections on Classification and Bootstrapping

Don't read Section 5.1.5 or Section 5.2!
:::

### Reading Guide

üìù [Download the Word Document](reading-guide/week-2a.docx)

::: callout-note
# Submission

Submit your completed reading guide to the Canvas assignment portal!
:::

## Concept Quiz -- No quiz this week, just the reading guide!

# K-Nearest Neighbors

The second chapter we will focus on discusses k-nearest neighbors!

## Textbook Reading

üìñ **Required Reading:** *ISLR -- Chapter 3, Section 5*

::: callout-tip
# Reread Carefully!

It is possible you already skimmed this section, but we are dedicating time specifically to this section this week, so I would encourage you to reread the **entire** section more carefully.
:::

### Reading Guide 

No reading guide for this section, only a concept quiz!

## K-Nearest Neighbors Video 

Here's a helpful video which explains how k-Nearest Neighbors works: <https://www.youtube.com/watch?v=HVXime0nQeI>

## Concept Quiz

**Question 1** -- [Parametric / Nonparametric] methods make strong assumptions about the functional form of $f(X)$, whereas [parametric / nonparametric] methods do not make assumptions about the functional form of $f(X)$. Linear regression is an example of a [parametric / nonparametric] method and k-nearest neighbors is an example of a [parametric / nonparametric] method.

**Question 2** -- A small value for $k$ results in a model with [low / high] bias and [low / high] variance. A large value for $k$ results in a model with [low / high] bias and [low / high] variance.


**Question 3** --If the true relationship is linear, k-nearest neighbors will always perform [better / worse] than linear regression.


**Question 4** -- If the true relationship is highly non-linear, k-nearest neighbors will [always / sometimes / never] perform worse than linear regression.


