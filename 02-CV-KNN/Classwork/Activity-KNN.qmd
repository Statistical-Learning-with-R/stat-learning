---
title: "K Nearest Neighbors"
author: "YOUR NAME HERE"
format: 
  html:
    code-fold: true
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: source
execute:
  message: false
---

## Setup

Declare your libraries:

```{r}
#| label: libraries-r
#| include: false

library(tidyverse)
library(tidymodels)
library(kknn)
```

```{r}
ins <- read_csv("https://www.dropbox.com/s/bocjjyo1ehr5auz/insurance.csv?dl=1")
```

## Activity Break 1: KNN modeling

#### Code from lecture

Establish our model:

```{r}
knn_mod <- nearest_neighbor(neighbors = 5) %>%
  set_mode("regression") %>% 
  set_engine("kknn")
```

Fit our model:

```{r}
knn_fit_1 <- knn_mod %>%
  fit(charges ~ age, data = ins)
```

Summarize our model:

```{r}
knn_fit_1$fit %>% summary()
```

#### Your task:

Use cross validation to choose between a KNN model with 5 neighbors that (1) uses only age versus (2) using both age and bmi.

How do these models compare to the least-squares regression approach from Tuesday?

How do these models compare to a KNN model with 10 neighbors?

## Activity Break 2: Normalizing variables

#### Code from lecture

Recipe:

```{r}
ins_rec <- recipe(charges ~ age + region, data = ins) %>%
  step_dummy(region)

ins_rec
```

Workflow:

```{r}
ins_wflow <- workflow() %>%
  add_recipe(ins_rec) %>%
  add_model(knn_mod)

ins_fit <- ins_wflow %>% fit(ins) 

ins_fit %>% pull_workflow_fit()
```

Normalize workflow:

```{r}
ins_rec <- recipe(charges ~ age + region, data = ins) %>%
  step_dummy(region) %>%
  step_normalize(age)

ins_wflow <- workflow() %>%
  add_recipe(ins_rec) %>%
  add_model(knn_mod)

ins_wflow
```

Fit:

```{r}
ins_fit <- ins_wflow %>% fit(ins) 

ins_fit %>% pull_workflow_fit()
```

#### Your task:

1.Make a KNN model with K = 5, using age, bmi, smoker, and sex 

2. Compare the model with non-normalized variables to one with normalized variables. Which is better?

## Activity Break 3: Tuning

#### Code from lecture

Set values to try:

```{r}
k_grid <- grid_regular(neighbors(c(1,50)), 
                       levels = 25)
k_grid

```

Make workflow:

```{r}
knn_mod_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

ins_rec <- recipe(charges ~ age + bmi + sex + smoker, data = ins) %>%
  step_dummy(all_nominal()) %>%
  step_normalize(all_numeric())

ins_wflow <- workflow() %>%
  add_recipe(ins_rec) %>%
  add_model(knn_mod_tune)
```

Fit cross-validations for all values of k:

```{r}
ins_cv <- vfold_cv(ins, v = 10)

knn_grid_search <-
  tune_grid(
    ins_wflow,
    resamples = ins_cv,
    grid = k_grid
  )
```

```{r}
knn_grid_search %>% collect_metrics()
```

```{r}
knn_grid_search %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  slice_min(mean)
```

```{r}
knn_grid_search %>% 
  collect_metrics() %>%
  ggplot(aes(x = neighbors, y = mean, color = .metric)) +
  geom_line()
```

#### Your task:

Find the best KNN model
